# ===============================
# AI Review .env example
# ===============================

# --- LLM ---
LLM__PROVIDER=OPENAI
LLM__PRICING_FILE=./pricing.yaml

# --- OpenAI specific ---
LLM__META__MODEL=gpt-4o-mini
LLM__META__MAX_TOKENS=1200
LLM__META__TEMPERATURE=0.3

# --- Gemini alternative ---
# LLM__META__MODEL=gemini-2.0-pro
# LLM__META__MAX_TOKENS=1200
# LLM__META__TEMPERATURE=0.3

# --- Claude alternative ---
# LLM__META__MODEL=claude-3-sonnet
# LLM__META__MAX_TOKENS=1200
# LLM__META__TEMPERATURE=0.3

# --- Ollama alternative ---
# LLM__PROVIDER=OLLAMA
# LLM__META__MODEL=llama2
# LLM__META__MAX_TOKENS=512
# LLM__META__TEMPERATURE=0.3
# LLM__META__NUM_CTX=2048
# LLM__META__TOP_P=0.9
# LLM__META__REPEAT_PENALTY=1.1
# LLM__META__STOP="USER:,SYSTEM:"
# LLM__META__SEED=42

# --- AWS Bedrock alternative ---
# LLM__PROVIDER=BEDROCK
# LLM__META__MODEL=anthropic.claude-3-sonnet-20240229-v1:0
# LLM__META__MAX_TOKENS=1200
# LLM__META__TEMPERATURE=0.3

# --- OpenRouter alternative ---
# LLM__PROVIDER=OPENROUTER
# LLM__META__MODEL=anthropic/claude-3.5-sonnet
# LLM__META__MAX_TOKENS=1200
# LLM__META__TEMPERATURE=0.3
# LLM__META__TITLE="AI Review"
# LLM__META__REFERER="https://your-domain.com"

# --- Azure OpenAI alternative ---
# LLM__PROVIDER=AZURE_OPENAI
# LLM__META__MODEL=gpt-4o-mini
# LLM__META__MAX_TOKENS=1200
# LLM__META__TEMPERATURE=0.3

# --- HTTP client for LLM ---
LLM__HTTP_CLIENT__VERIFY=true
LLM__HTTP_CLIENT__TIMEOUT=120
LLM__HTTP_CLIENT__API_URL=https://api.openai.com/v1
LLM__HTTP_CLIENT__API_TOKEN=${OPENAI_API_KEY}
LLM__HTTP_CLIENT__API_TOKEN_SCHEME=Bearer  # required only when LLM__HTTP_CLIENT__API_TOKEN is set

# For Claude (only if provider=CLAUDE)
# LLM__HTTP_CLIENT__API_URL=https://api.anthropic.com
# LLM__HTTP_CLIENT__API_TOKEN=${CLAUDE_API_KEY}
# LLM__HTTP_CLIENT__API_VERSION=2023-06-01

# For Gemini (only if provider=GEMINI)
# LLM__HTTP_CLIENT__API_URL=https://generativelanguage.googleapis.com
# LLM__HTTP_CLIENT__API_TOKEN=${GEMINI_API_KEY}

# For Ollama (only if provider=OLLAMA, no API token required)
# LLM__HTTP_CLIENT__API_URL=http://localhost:11434

# For Bedrock (only if provider=BEDROCK)
# LLM__HTTP_CLIENT__API_URL=https://bedrock-runtime.us-east-1.amazonaws.com
# LLM__HTTP_CLIENT__REGION=us-east-1
# LLM__HTTP_CLIENT__ACCESS_KEY=${AWS_ACCESS_KEY_ID}
# LLM__HTTP_CLIENT__SECRET_KEY=${AWS_SECRET_ACCESS_KEY}
# LLM__HTTP_CLIENT__SESSION_TOKEN=${AWS_SESSION_TOKEN}   # optional (STS / roles)

# For OpenRouter (only if provider=OPENROUTER)
# LLM__HTTP_CLIENT__API_URL=https://openrouter.ai/api/v1
# LLM__HTTP_CLIENT__API_TOKEN=${OPENROUTER_API_KEY}

# For Azure OpenAI (only if provider=AZURE_OPENAI)
# LLM__HTTP_CLIENT__API_URL=https://<your-resource>.openai.azure.com
# LLM__HTTP_CLIENT__API_TOKEN=${AZURE_OPENAI_API_KEY}
# LLM__HTTP_CLIENT__API_VERSION=2024-06-01

# --- VCS ---
VCS__PROVIDER=GITLAB

VCS__PAGINATION__PER_PAGE=100
VCS__PAGINATION__MAX_PAGES=5

# --- GitLab ---
VCS__PIPELINE__PROJECT_ID=${CI_PROJECT_ID}
VCS__PIPELINE__MERGE_REQUEST_ID=${CI_MERGE_REQUEST_IID}

VCS__HTTP_CLIENT__VERIFY=true
VCS__HTTP_CLIENT__TIMEOUT=120
VCS__HTTP_CLIENT__API_URL=${CI_SERVER_URL}
VCS__HTTP_CLIENT__API_TOKEN=${CI_JOB_TOKEN}
VCS__HTTP_CLIENT__API_TOKEN_SCHEME=Bearer  # required only when VCS__HTTP_CLIENT__API_TOKEN is set

# --- GitHub ---
# VCS__PROVIDER=GITHUB
#
# VCS__PIPELINE__OWNER=${GITHUB_REPOSITORY_OWNER}
# VCS__PIPELINE__REPO=${GITHUB_REPOSITORY_NAME}
# VCS__PIPELINE__PULL_NUMBER=${PR_NUMBER}
#
# VCS__HTTP_CLIENT__TIMEOUT=120
# VCS__HTTP_CLIENT__API_URL=https://api.github.com
# VCS__HTTP_CLIENT__API_TOKEN=${GITHUB_TOKEN}

# --- Bitbucket Cloud ---
# VCS__PROVIDER=BITBUCKET_CLOUD
#
# VCS__PIPELINE__WORKSPACE=${BITBUCKET_WORKSPACE}
# VCS__PIPELINE__REPO_SLUG=${BITBUCKET_REPO_SLUG}
# VCS__PIPELINE__PULL_REQUEST_ID=${BITBUCKET_PR_ID}
#
# VCS__HTTP_CLIENT__TIMEOUT=120
# VCS__HTTP_CLIENT__API_URL=https://api.bitbucket.org/2.0
# VCS__HTTP_CLIENT__API_TOKEN=${BITBUCKET_TOKEN}

# --- Bitbucket Server ---
# VCS__PROVIDER=BITBUCKET_SERVER
#
# VCS__PIPELINE__PROJECT_KEY=${BITBUCKET_PROJECT_KEY}
# VCS__PIPELINE__REPO_SLUG=${BITBUCKET_REPO_SLUG}
# VCS__PIPELINE__PULL_REQUEST_ID=${BITBUCKET_PR_ID}
#
# VCS__HTTP_CLIENT__TIMEOUT=120
# VCS__HTTP_CLIENT__API_URL=https://bitbucket.mycompany.com/rest/api/1.0
# VCS__HTTP_CLIENT__API_TOKEN=${BITBUCKET_SERVER_TOKEN}

# --- Azure DevOps ---
# VCS__PROVIDER=AZURE_DEVOPS
#
# VCS__PIPELINE__ORGANIZATION=${SYSTEM_COLLECTIONURI}
# VCS__PIPELINE__PROJECT=${SYSTEM_TEAMPROJECT}
# VCS__PIPELINE__REPOSITORY_ID=${BUILD_REPOSITORY_ID}
# VCS__PIPELINE__PULL_REQUEST_ID=${SYSTEM_PULLREQUEST_PULLREQUESTID}
# VCS__PIPELINE__ITERATION_ID=${SYSTEM_PULLREQUEST_ITERATIONID}
#
# VCS__HTTP_CLIENT__VERIFY=true
# VCS__HTTP_CLIENT__TIMEOUT=120
# VCS__HTTP_CLIENT__API_URL=https://dev.azure.com/${AZURE_ORG_NAME}
# VCS__HTTP_CLIENT__API_TOKEN=${AZURE_DEVOPS_PAT}
# VCS__HTTP_CLIENT__API_TOKEN_TYPE=OAUTH2
# VCS__HTTP_CLIENT__API_VERSION=7.0

# --- Gitea ---
# VCS__PROVIDER=GITEA
#
# VCS__PIPELINE__OWNER=${GITEA_REPOSITORY_OWNER}
# VCS__PIPELINE__REPO=${GITEA_REPOSITORY_NAME}
# VCS__PIPELINE__PULL_NUMBER=${PR_NUMBER}
#
# VCS__HTTP_CLIENT__TIMEOUT=120
# VCS__HTTP_CLIENT__API_URL=https://gitea.mycompany.com/api/v1
# VCS__HTTP_CLIENT__API_TOKEN=${GITEA_TOKEN}
# VCS__HTTP_CLIENT__API_TOKEN_SCHEME=token

# --- Core ---
CORE__CONCURRENCY=7

# --- Prompts ---
PROMPT__CONTEXT__ENVIRONMENT=staging
PROMPT__CONTEXT__COMPANY_NAME="ACME Corp"
PROMPT__CONTEXT__CI_PIPELINE_URL=https://gitlab.com/pipelines/123

PROMPT__CONTEXT_PLACEHOLDER="<<{value}>>"

PROMPT__NORMALIZE_PROMPTS=true

PROMPT__INLINE_PROMPT_FILES='["./prompts/default_inline.md"]'
PROMPT__CONTEXT_PROMPT_FILES='["./prompts/default_context.md"]'
PROMPT__SUMMARY_PROMPT_FILES='["./prompts/default_summary.md"]'
PROMPT__INLINE_REPLY_PROMPT_FILES='["./prompts/default_inline_reply.md"]'
PROMPT__SUMMARY_REPLY_PROMPT_FILES='["./prompts/default_summary_reply.md"]'

PROMPT__SYSTEM_INLINE_PROMPT_FILES='["./prompts/default_system_inline.md"]'
PROMPT__SYSTEM_CONTEXT_PROMPT_FILES='["./prompts/default_system_context.md"]'
PROMPT__SYSTEM_SUMMARY_PROMPT_FILES='["./prompts/default_system_summary.md"]'
PROMPT__SYSTEM_INLINE_REPLY_PROMPT_FILES='["./prompts/default_system_inline_reply.md"]'
PROMPT__SYSTEM_SUMMARY_REPLY_PROMPT_FILES='["./prompts/default_system_summary_reply.md"]'

PROMPT__INCLUDE_INLINE_SYSTEM_PROMPTS=true
PROMPT__INCLUDE_CONTEXT_SYSTEM_PROMPTS=true
PROMPT__INCLUDE_SUMMARY_SYSTEM_PROMPTS=true
PROMPT__INCLUDE_INLINE_REPLY_SYSTEM_PROMPTS=true
PROMPT__INCLUDE_SUMMARY_REPLY_SYSTEM_PROMPTS=true

# --- Review ---
# Available modes:
#   FULL_FILE_DIFF
#   FULL_FILE_CURRENT
#   FULL_FILE_PREVIOUS
#   ONLY_ADDED
#   ONLY_REMOVED
#   ADDED_AND_REMOVED
#   ONLY_ADDED_WITH_CONTEXT
#   ONLY_REMOVED_WITH_CONTEXT
#   ADDED_AND_REMOVED_WITH_CONTEXT
REVIEW__MODE=FULL_FILE_DIFF

REVIEW__DRY_RUN=false
REVIEW__INLINE_TAG="#ai-review-inline"
REVIEW__INLINE_REPLY_TAG="#ai-review-inline-reply"
REVIEW__SUMMARY_TAG="#ai-review-summary"
REVIEW__SUMMARY_REPLY_TAG="#ai-review-summary-reply"
REVIEW__CONTEXT_LINES=10
REVIEW__ALLOW_CHANGES=
REVIEW__IGNORE_CHANGES=
REVIEW__MAX_INLINE_COMMENTS=
REVIEW__MAX_CONTEXT_COMMENTS=
REVIEW__REVIEW_ADDED_MARKER=" # added"
REVIEW__REVIEW_REMOVED_MARKER=" # removed"
REVIEW__INLINE_COMMENT_FALLBACK=true

# --- Logger ---
# Options: NOTSET | DEBUG | INFO | WARNING | ERROR | CRITICAL
LOGGER__LEVEL=INFO
LOGGER__FORMAT="{time:YYYY-MM-DD HH:mm:ss} | {level} | {extra[logger_name]} | {message}"

# --- Artifacts ---
ARTIFACTS__LLM_DIR=./artifacts/llm
ARTIFACTS__VCS_DIR=./artifacts/vcs
ARTIFACTS__LLM_ENABLED=false
ARTIFACTS__VCS_ENABLED=false
